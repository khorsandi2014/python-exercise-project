{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR_solution.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYMTVF1ACJ04ML3Y+SBW3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khorsandi2014/python-exercise-project/blob/main/OCR_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UFyY9HH240T"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Detection and Extraction using OpenCV and OCR\n",
        "\n",
        "OpenCV (Open source computer vision) is a library of programming functions mainly aimed at real-time computer vision. OpenCV in python helps to process an image and apply various functions like resizing image, pixel manipulations, object detection, etc. In this article, we will learn how to use contours to detect the text in an image and save it to a text file.\n",
        "Required Installations:\n",
        "\n",
        "\n",
        "pip install opencv-python\n",
        "pip install pytesseract\n",
        "\n",
        "OpenCV package is used to read an image and perform certain image processing techniques. Python-tesseract is a wrapper for Google’s Tesseract-OCR Engine which is used to recognize text from images.\n",
        "Download the tesseract executable file from this link.\n",
        "Approach: \n",
        "After the necessary imports, a sample image is read using the imread function of opencv.\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "ejT8BnoA25gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying image processing for the image:\n",
        "\n",
        "The colorspace of the image is first changed and stored in a variable. For color conversion we use the function cv2.cvtColor(input_image, flag). The second parameter flag determines the type of conversion. We can chose among cv2.COLOR_BGR2GRAY and cv2.COLOR_BGR2HSV. cv2.COLOR_BGR2GRAY helps us to convert an RGB image to gray scale image and cv2.COLOR_BGR2HSV is used to convert an RGB image to HSV (Hue, Saturation, Value) color-space image. Here, we use cv2.COLOR_BGR2GRAY. A threshold is applied to the converted image using cv2.threshold function. \n",
        "There are 3 types of thresholding: \n",
        " \n",
        "\n",
        "Simple Thresholding\n",
        "Adaptive Thresholding\n",
        "Otsu’s Binarization\n",
        "For more information on thresholding, refer Thresholding techniques using OpenCV.\n",
        "cv2.threshold() has 4 parameters, first parameter being the color-space changed image, followed by the minimum threshold value, the maximum threshold value and the type of thresholding that needs to be applied.\n",
        " \n",
        "\n",
        "To get a rectangular structure:\n",
        "cv2.getStructuringElement() is used to define a structural element like elliptical, circular, rectangular etc. Here, we use the rectangular structural element (cv2.MORPH_RECT). cv2.getStructuringElement takes an extra size of the kernel parameter. A bigger kernel would make group larger blocks of texts together. After choosing the correct kernel, dilation is applied to the image with cv2.dilate function. Dilation makes the groups of text to be detected more accurately since it dilates (expands) a text block.\n"
      ],
      "metadata": {
        "id": "26KuDVl53V7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Contours:\n",
        "\n",
        "cv2.findContours() is used to find contours in the dilated image. There are three arguments in cv.findContours(): the source image, the contour retrieval mode and the contour approximation method. \n",
        "This function returns contours and hierarchy. Contours is a python list of all the contours in the image. Each contour is a Numpy array of (x, y) coordinates of boundary points in the object. Contours are typically used to find a white object from a black background. All the above image processing techniques are applied so that the Contours can detect the boundary edges of the blocks of text of the image. A text file is opened in write mode and flushed. This text file is opened to save the text from the output of the OCR."
      ],
      "metadata": {
        "id": "K7ktMeMh3bK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying OCR:\n",
        "\n",
        "Loop through each contour and take the x and y coordinates and the width and height using the function cv2.boundingRect(). Then draw a rectangle in the image using the function cv2.rectangle() with the help of obtained x and y coordinates and the width and height. There are 5 parameters in the cv2.rectangle(), the first parameter specifies the input image, followed by the x and y coordinates (starting coordinates of the rectangle), the ending coordinates of the rectangle which is (x+w, y+h), the boundary color for the rectangle in RGB value and the size of the boundary. Now crop the rectangular region and then pass it to the tesseract to extract the text from the image. Then we open the created text file in append mode to append the obtained text and close the file.\n",
        "Sample image used for the code: "
      ],
      "metadata": {
        "id": "WuEpn70Q3trk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](sample4.jpeg \"Text Image\")"
      ],
      "metadata": {
        "id": "OWzPRlcc4GCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "!sudo apt update\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "id": "QhABTgiY5rMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import cv2\n",
        "import pytesseract\n",
        " \n",
        "# Mention the installed location of Tesseract-OCR in your system\n",
        "pytesseract.pytesseract.tesseract_cmd = 'System_path_to_tesseract.exe'\n",
        " \n",
        "# Read image from which text needs to be extracted\n",
        "img = cv2.imread(\"./sample4.jpeg\")\n",
        "print(type(img))\n",
        "# Preprocessing the image starts\n",
        " \n",
        "# Convert the image to gray scale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "# Performing OTSU threshold\n",
        "ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
        " \n",
        "# Specify structure shape and kernel size.\n",
        "# Kernel size increases or decreases the area\n",
        "# of the rectangle to be detected.\n",
        "# A smaller value like (10, 10) will detect\n",
        "# each word instead of a sentence.\n",
        "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18))\n",
        " \n",
        "# Applying dilation on the threshold image\n",
        "dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n",
        " \n",
        "# Finding contours\n",
        "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,\n",
        "                                                 cv2.CHAIN_APPROX_NONE)\n",
        " \n",
        "# Creating a copy of image\n",
        "im2 = img.copy()\n",
        " \n",
        "# A text file is created and flushed\n",
        "file = open(\"recognized.txt\", \"w+\")\n",
        "file.write(\"\")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "046mLZ6m6KNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = (r'/usr/bin/tesseract')"
      ],
      "metadata": {
        "id": "2592Ngci9jrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which tesseract\n"
      ],
      "metadata": {
        "id": "HwHs1mV-6wUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Looping through the identified contours\n",
        "# Then rectangular part is cropped and passed on\n",
        "# to pytesseract for extracting text from it\n",
        "# Extracted text is then written into the text file\n",
        "for cnt in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "     \n",
        "    # Drawing a rectangle on copied image\n",
        "    rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "     \n",
        "    # Cropping the text block for giving input to OCR\n",
        "    cropped = im2[y:y + h, x:x + w]\n",
        "     \n",
        "    # Open the file in append mode\n",
        "    file = open(\"recognized.txt\", \"a\")\n",
        "     \n",
        "    # Apply OCR on the cropped image\n",
        "    text = pytesseract.image_to_string(cropped)\n",
        "     \n",
        "    # Appending the text into file\n",
        "    file.write(text)\n",
        "    file.write(\"\\n\")\n",
        "     \n",
        "    # Close the file\n",
        "    file.close"
      ],
      "metadata": {
        "id": "Fq0g9o_73Vb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2_pkkZhA9qjd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}